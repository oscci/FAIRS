---
title: "FAIRS report, Rounds 1 and 2"
author: "Dorothy V. M. Bishop"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: null
  word_document: 
    reference_docx: word-styles-reference-01.docx
---

<!---  Numerical data only, no free text comments -->


```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(viridis)
require(here)
require(janitor)
require(tidyr)
library(stringr)
require(flextable)
require(explore) #not needed but helps to visualise data
require(DescTools)


```
<!--- https://rmarkdown.rstudio.com/articles_docx.html for page numbers-->



```{r readcleaneddata, echo = F}
datadict <- read.csv('DataDictionary_Rounds_1_2_csv.csv')
#remove the blank rows from data dictionary which are just there for ease of reading in excel.
w<- which(is.na(datadict$column)) 
datadict<-datadict[-w,]
row.names(datadict)<-1:nrow(datadict)

df <- read.csv('FAIRS_Rounds1_2.csv')

```

```{r orderedfactors, echo=FALSE}
#make ordered factors for mult choice items
ordfac <- function(df,colnum,myorder){
  uniques <- unique(df[,colnum])
  df[,colnum]<-factor(df[,colnum],ordered=TRUE,levels=uniques[myorder])
  return(df)
}

#These are hard-coded : check each column using unique to find how the responses are ordered, then manually reorder
#THIS WILL ONLY WORK WITH DF CREATED FROM THIS CSV IN THIS ORDER!

#NB NA will be included in the unique list, and is omitted here

df<-ordfac(df,colnum = 10, myorder = c(3,1,2))
df<-ordfac(df,colnum = 33, myorder = c(1,2,3))
df<-ordfac(df,colnum = 34, myorder = c(5,4,1,2,3))
df<-ordfac(df,colnum = 39, myorder = c(3,2,1))
df<-ordfac(df,colnum = 40, myorder = c(3,2,1))
df<-ordfac(df,colnum = 64, myorder = c(3,2,1))
df<-ordfac(df,colnum = 65, myorder = c(2,4,1))
df<-ordfac(df,colnum = 87, myorder = c(6,1,4,2,5))
df<-ordfac(df,colnum = 95, myorder = c(4,5,1,2))
df<-ordfac(df,colnum = 96, myorder = c(6,5,4,2,1))

df[,5]<-factor(df[,5])
df[,6]<-factor(df[,6])
```

```{r recodeitem9_12}
#Item 9 was rank ordered in round 1, with 1 as first choice. But this confused respondents, and for compatibility with scoring, it is reversed here.
#Item 12 had a similar issue - and it was rather ambiguous as to whether respondents should rank order or rate.
 w<-which(grepl('1_item9',names(df))==TRUE)
df[,w]<-5-df[,w]
 w<-which(grepl('1_item12',names(df))==TRUE)
df[,w]<-6-df[,w]
```
## Summary of FAIRS Survey, rounds 1 and 2

For background to the survey, please see the protocol here: <https://osf.io/rycqb/>.  
For interim reports from Rounds 1 and 2 that include free text comments please see here: <https://osf.io/mzjsh/>.   


```{r numformat,echo=F}
#Format numbers so they have same n decimal places, even if zero at end
#This returns a string

numformat=function(mynum,ndecimals){
  newnum <- format(round(mynum,ndecimals),nsmall=ndecimals)
  return(newnum)
}

```

```{r myhighlight, echo=F}
addhighlight <- function(myft){
  cutoff1 <- 70 #setting cutoff dynamically doesn't work for some reason, so they are hard coded below
  cutoff2 <- 50
  color4 <- 'red'
  color3 <-'pink'
  color2 <- 'lightblue'
  color1 <- 'cornflowerblue'

#This miscodes any row with 100 in it.  I think this has to do with values being text rather than numeric, (for formatting purposes) but various attempts to fix it have failed.  Need to correct manually

  myft <- highlight(myft, j = 2, i = ~ `S` > 49.999, color = color2)
  myft <- highlight(myft, j = 2, i = ~ `S` > 70.0, color = color1)
  myft <- highlight(myft, j = 2, i = ~ `S` < 50.0, color = color3)
  myft <- highlight(myft, j = 2, i = ~ `S` < 30.0, color = color4)
  
  
  myft <- highlight(myft, j = 3, i = ~ `R` > 49.999, color = color2)
  myft <- highlight(myft, j = 3, i = ~ `R` > 70.0, color = color1)
  myft <- highlight(myft, j = 3, i = ~ `R` < 50.0, color = color3)
  myft <- highlight(myft, j = 3, i = ~ `R` < 30.0, color = color4)
  
  
  
  myft <- highlight(myft, j = 4, i = ~ `O` > 49.999, color = color2)
  myft <- highlight(myft, j = 4, i = ~ `O` > 70.0, color = color1)
  myft <- highlight(myft, j = 4, i = ~ `O` < 50.0, color = color3)
  myft <- highlight(myft, j = 4, i = ~ `O` < 30.0, color = color4)
  
  myft <- highlight(myft, j = 5, i = ~ All > 49.999, color = color2)
  myft <- highlight(myft, j = 5, i = ~ All > 70.0, color = color1)
  myft <- highlight(myft, j = 5, i = ~ All < 50.0, color = color3)
  myft <- highlight(myft, j = 5, i = ~ All < 30.0, color = color4)
  
  return(myft)
} 
```

```{r multchtab, echo=FALSE}
makemc <- function(df,w,groupcol,mycaption){
  rawtab <- table(df[,w],df[,groupcol])
  rawdf<-as.data.frame.matrix(rawtab)
  rawdf$All<-rowSums(rawdf[,1:3])
  sumtab <-as.data.frame.matrix(100*prop.table(as.matrix(rawdf),2))
  sumtab <- numformat(sumtab,1)
  sumtab<-cbind(row.names(sumtab),sumtab)
  names(sumtab) <- c('Multiple choice option','S','R','O','All')

  return(sumtab)
}
```

```{r percentageagree, echo = FALSE}
#thisrow is 0 for generic report; otherwise specifies the panellist
propagree <- function(df,col1,col2, maxval,groupcol, mycaption){ 
  
  
  w <- col2-col1+1 #N subitems
  thisbit <- as.data.frame(df[,col1:col2])
  
  agreetab<-data.frame(matrix (NA, nrow=w,ncol=5))
  names(agreetab)<-c('Subitem','S','R','O','All')
  myoptions <- 1:maxval
  
  #Check for 5 point scale and collapse extremes
  if(maxval==5){
    myoptions <-c(1.5,3,4.5)
    for(v in 1:w){
      ww<-which(thisbit[,v]==4)
      thisbit[ww,v] <- 5   
      ww<-which(thisbit[,v]==2)
      thisbit[ww,v] <- 1 
    }
  }
  
  # #Check for 4 point scale and add one, so 2 most extreme become 4-5
  # if(maxval==4){
  #   for(v in 1:w){
  #     
  #     thisbit[,v] <- thisbit[,v]  +1
  #     }
  #   }
    
    for (v in 1:w){ #stepping through subitems
      thistab <- table(thisbit[,v],df[,groupcol])
      thistab <- cbind(thistab,table(thisbit[,v])) #last col has All cases
      ptab <- prop.table(thistab,2) #percentage of each response by group (2nd num indicates col percentage rather than row)
   
    agreetab[v,2:5]<-numformat(100*ptab[nrow(ptab),],1)

    agreetab[v,1]<-paste0(LETTERS[v],") ",datadict$name.1[(col1+v-1)])
  
    }

    return(agreetab)
}
```



```{r allitems, echo=F}

#FOR REASONS BEYOND MY COMPREHENSION THIS WON'T WORK IN A LOOP. NO OUTPUT.
#SO HAVE TO CALL IT ITEM BY ITEM
maketable<-function(df,i,r){
  thisbit<-paste0(r,"_item",i)
  thiscaption<-paste0("Round ",r,": Item ",i)
   w<-which(grepl(thisbit,names(df))==TRUE)
   if(length(w)==1){  
   mytab<-makemc(df,w,groupcol=6,thiscaption)
   }
   if(length(w)>1){
    col1=min(w)
    col2=max(w)
    mytab<-propagree(df,col1,col2, maxval = length(w),groupcol=6,thiscaption)
   }
    myft <- flextable(as.data.frame(mytab))
    myft <- set_caption(myft, thiscaption)
    myft <- addhighlight(myft) 
 
    myft <- set_table_properties(myft,layout="autofit")
    myft
return(myft)
}
```

# Burdens of serious research misconduct  
## ITEM 2  
Round 1 and 2: How common is the problem of serious research misconduct? (select one) *

`r myft<-maketable(df,2,1)`
`r myft`
`r myft<-maketable(df,2,2)`
`r myft`

## ITEM 3
Round 1 and 2: How harmful are the impacts of serious research misconduct to different segments of society? Please code as 1 (low harm) to 5 (strong harm) 
`r myft<-maketable(df,3,1)`
`r myft`
`r myft<-maketable(df,3,2)`
`r myft`

## Goals of those responding to serious research misconduct  

## ITEM 4
Round 1: In responding to serious research misconduct, several goals may be considered.
Please rate how important each of these is, from 1 (unimportant) to 4 (very important) 
`r myft<-maketable(df,4,1)`
`r myft`
Round 2: In responding to serious research misconduct, several goals may be considered.
Please rate how important each of these is, from 1 (unimportant) to 5 (very important)

`r myft<-maketable(df,4,2)`
`r myft`

# Factors hindering academic institutions' response to serious research misconduct  
## ITEM 5
Rounds 1 and 2: Various factors may hinder academic institutions' response to serious research
misconduct. Please rate the following from 1 (not much of a hindrance) to 5 (substantial hindrance)

`r myft<-maketable(df,5,1)`
`r myft`
`r myft<-maketable(df,5,2)`
`r myft`

# Factors driving serious research misconduct
## ITEM 6

 What is the impact of these factors in encouraging researchers to commit serious research misconduct? Please rate from 1 (little impact) to 5 (large impact).
 
 `r myft<-maketable(df,6,1)`
`r myft`
`r myft<-maketable(df,6,2)`
`r myft`  

# Role of post-publication peer review  
## ITEM 7  
Round 1: On balance, the role of social media in detecting and reporting serious research misconduct has been: (select one) 
 `r myft<-maketable(df,7,1)`
`r myft`

Round 2: Please rate the impact of the following from 1 = strongly negative to 5 = strongly positive in drawing attention to serious academic misconduct

 `r myft<-maketable(df,7,2)`
`r myft`

# Reporting serious research misconduct
## ITEM 8
Round 1: Official channels for reporting misconduct are often slow and obstructive (select one option) 
 `r myft<-maketable(df,8,1)`
`r myft`

Round 2:  Official channels for reporting misconduct seldom work efficiently 
 `r myft<-maketable(df,8,2)`
`r myft`

# Models for addressing serious research misconduct  
## ITEM 9

Round 1: Rank these in order from 1 = most preferred, to 4 = least preferred.  
N.B. Several respondents noted this was confusing, because when RANKING options, 1 was regarded as most preferred, whereas elsewhere a high rating corresponded to positive preference. This item was recoded prior to analysis (see above), so the percentages in the Table show those ranking 1. The format was changed in Round 2.
 `r myft<-maketable(df,9,1)`
`r myft`

Round 2: In an ideal world where resources are not an issue, which is the most suitable model/system for addressing serious research misconduct?
Rate these options where 1 = least preferred and 5 = most preferred.  
Note that additional options were added in Round 2, based on responses to Round 1.
(Despite the change in wording, at least one respondent thought they were being asked to rank order the options, rather than rate them). 

 `r myft<-maketable(df,9,2)`
`r myft`

# Role of employers
## Item 10
Rounds 1 and 2: Prospective employers should undertake rigorous due diligence and, as far as possible, check with previous employers to ask if there have been any investigations into serious research misconduct (multiple choice options). The Agree option was split in Round 2 on the basis of comments from Round 1.

 `r myft<-maketable(df,10,1)`
`r myft`
 `r myft<-maketable(df,10,2)`
`r myft`

# Legal obligations of employers
## Item 11
Rounds 1 and 2: Employers, funders and publishers of research should be legally required to share information to support investigations of serious research misconduct.  (3 point scale for Round 1 changed to 5 point scale for Round 2, for consistency with other ratings).

 `r myft<-maketable(df,11,1)`
`r myft`
 `r myft<-maketable(df,11,2)`
`r myft`

# Solutions to serious research misconduct
## ITEM 12
Rounds 1 and 2: Given that we have finite resources, which solutions to serious research misconduct should be prioritised in funding? In Round 1, the options were worded as 1 = most preferred, to 5 = least preferred, whereas in Round 2, they were 1 = totally ineffective to 5 = highly effective. With hindsight this was very confusing, and respondents in Round 1 may have interpreted this as a request to rank order the options. As noted above, the Round 1 scores are rescaled so that the table shows those rating the option as 1 or 2. 

 `r myft<-maketable(df,12,1)`
`r myft`
 `r myft<-maketable(df,12,2)`
`r myft`

# Role of publishers
# ITEM 13. 
Round 1: It is not the responsibility of publishers or journal editors to determine whether serious research misconduct has occurred, but they are responsible for ensuring the literature is decontaminated from erroneous work promptly. Please rate the following statements in accordance with your views on how this should work, from 1 = strongly disagree to 5 = strongly agree. 
 `r myft<-maketable(df,13,1)`
`r myft`

For Round 2, the wording was modified because some respondents objected to the premise of the first sentence.  Accordingly, this statement was incorporated as another subitem.  However, that proved to be a poor decision, as it involved rating a negatively worded item, which can be confusing. 
The revised wording for the item was: Publishers and their journal editors are responsible for ensuring the literature is decontaminated from erroneous work promptly. Please rate the following statements in accordance with your views on how this should work, from 1 = strongly disagree to 5 = strongly agree.  

`r myft<-maketable(df,13,2)`
`r myft`

# Whistleblowers and bystanders
## ITEM 14
Rounds 1 and 2: Please rate your agreement with the following statements about whistleblowers from 1 = strongly disagree to 5 = strongly agree. The last two subitems were reordered in Round 2, as the 'collateral damage' issue seemed separate from the other issues. 

`r myft<-maketable(df,14,1)`
`r myft`
`r myft<-maketable(df,14,2)`
`r myft`

# When serious research misconduct is confirmed  
## ITEM 15
Rounds 1 and 2: Which of these practices should be options for institutions when serious research misconduct is confirmed.
Please give your rating from 1 = strongly disagree to 5 = strongly agree

`r myft<-maketable(df,15,1)`
`r myft`
`r myft<-maketable(df,15,2)`
`r myft`

# Unintended consequences/barriers to progress
## ITEM 16
Rounds 1 and 2: Please rate your agreement with the following statements about unintended consequences/barriers to progress from 1 = strongly disagree to 5 = strongly agree.  In Round 2, an explanation was added in response to a comment on Round 1, stating "This question is about what you perceive as the current state of affairs."

`r myft<-maketable(df,16,1)`
`r myft`
`r myft<-maketable(df,16,2)`
`r myft`

# Final item
## ITEM 17
Round 1: "One of the likely drivers of trust and distrust in research is the way research institutes, publishers, and funders respond to allegations of research misconduct" (Bouter, 2024). This item was intended to get a final overall impression of the key issues in the field. 
`r myft<-maketable(df,17,1)`
`r myft` 

Round 2: To conclude the survey, respondents were invited to express their interest in a range of possible topics for discussion, i.e. How interested would you be in having discussion of the following topics at the in-person meeting in April?  Rate from 1 = not at all interested to 5 strongly interested.  

`r myft<-maketable(df,17,2)`
`r myft` 








